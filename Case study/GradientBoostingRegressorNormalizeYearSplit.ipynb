{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from clean_data import clean_data, prepare_data\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "train = pd.read_csv('../cars-competition/data/cars_train.csv', index_col='Id')\n",
    "submission = pd.read_csv('../cars-competition/data/cars_test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning cylinders...\n",
      "Cleaning condition...\n",
      "Cleaning odometer...\n",
      "Cleaning drive...\n",
      "Cleaning size...\n",
      "Cleaning manufacturer...\n",
      "Cleaning fuel...\n",
      "Cleaning transmission...\n",
      "Cleaning title status...\n",
      "Data cleaning complete!\n",
      "Cleaning cylinders...\n",
      "Cleaning condition...\n",
      "Cleaning odometer...\n",
      "Cleaning drive...\n",
      "Cleaning size...\n",
      "Cleaning manufacturer...\n",
      "Cleaning fuel...\n",
      "Cleaning transmission...\n",
      "Cleaning title status...\n",
      "Data cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "# Clean Data\n",
    "train = clean_data(train)\n",
    "submission = clean_data(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data preparation complete!\n",
      "Preparing data...\n",
      "Data preparation complete!\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "# columns = ['year','manufacturer','condition','cylinders','fuel','odometer','title_status','transmission','drive','size']\n",
    "columns = ['year','manufacturer','condition','cylinders','odometer','title_status','transmission','size','lat','long']\n",
    "X, y = prepare_data(train,columns,typ='train')\n",
    "X_sub, _ = prepare_data(submission,columns,typ='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by year\n",
    "def yearSplit(X,y=pd.DataFrame(None)):\n",
    "    decade = {i:(i*10+1900,i*10+1909) for i in range(12)}\n",
    "    y_decade = {}\n",
    "    for i in decade.keys():\n",
    "        print('Spliting data by decade: {}'.format(decade[i]))\n",
    "        dec = (X['year']>=decade[i][0]) & (X['year']<=decade[i][1])\n",
    "        decade[i] = X[dec]\n",
    "        if any(y != None):\n",
    "            y_decade[i] = y[dec]\n",
    "    return decade, y_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting Train\n",
      "Spliting data by decade: (1900, 1909)\n",
      "Spliting data by decade: (1910, 1919)\n",
      "Spliting data by decade: (1920, 1929)\n",
      "Spliting data by decade: (1930, 1939)\n",
      "Spliting data by decade: (1940, 1949)\n",
      "Spliting data by decade: (1950, 1959)\n",
      "Spliting data by decade: (1960, 1969)\n",
      "Spliting data by decade: (1970, 1979)\n",
      "Spliting data by decade: (1980, 1989)\n",
      "Spliting data by decade: (1990, 1999)\n",
      "Spliting data by decade: (2000, 2009)\n",
      "Spliting data by decade: (2010, 2019)\n",
      "Spliting Test\n",
      "Spliting data by decade: (1900, 1909)\n",
      "Spliting data by decade: (1910, 1919)\n",
      "Spliting data by decade: (1920, 1929)\n",
      "Spliting data by decade: (1930, 1939)\n",
      "Spliting data by decade: (1940, 1949)\n",
      "Spliting data by decade: (1950, 1959)\n",
      "Spliting data by decade: (1960, 1969)\n",
      "Spliting data by decade: (1970, 1979)\n",
      "Spliting data by decade: (1980, 1989)\n",
      "Spliting data by decade: (1990, 1999)\n",
      "Spliting data by decade: (2000, 2009)\n",
      "Spliting data by decade: (2010, 2019)\n"
     ]
    }
   ],
   "source": [
    "# Split data by year\n",
    "print('Spliting Train')\n",
    "X_dec,y_dec = yearSplit(X,y)\n",
    "print('Spliting Test')\n",
    "X_sub_dec,_ = yearSplit(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize columns\n",
    "norm = ['year','condition','cylinders','odometer','lat','long']\n",
    "for i, X in X_dec.items():\n",
    "    X[norm] = normalize(X[norm])\n",
    "for i, X_sub in X_sub_dec.items():\n",
    "    X_sub[norm] = normalize(X_sub[norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature reduction PCA\n",
    "n_components = [5,10,15,20,25,30,35,40]\n",
    "#n_components = [5,10,15]\n",
    "X_new_dec = {}\n",
    "pca = {}\n",
    "for i, X in X_dec.items():\n",
    "    new = {}\n",
    "    pca_n = {}\n",
    "    for n in n_components:\n",
    "        try:\n",
    "            pca_n[n] = PCA(n_components = n)\n",
    "            X_new = pca_n[n].fit_transform(X)\n",
    "        except:\n",
    "            pass\n",
    "        new[n] = X_new\n",
    "    X_new_dec[i] = new\n",
    "    pca[i] = pca_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test\n",
    "train_test_dec = {}\n",
    "for i, dic in X_new_dec.items():\n",
    "    train_test_n = {}\n",
    "    for j, X_new in dic.items():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_new,y_dec[i],test_size=0.2,random_state=200)\n",
    "        train_test_n[j] = [X_train, X_test, y_train, y_test]\n",
    "    train_test_dec[i] = train_test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9d2880571937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgradb_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mgradb_reg_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradb_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgradb_reg_dec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradb_reg_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1545\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1608\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1609\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1244\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GradientBoostingRegressor\n",
    "gradb_reg_dec = {}\n",
    "for i, dic in train_test_dec.items():\n",
    "    gradb_reg_n = {}\n",
    "    for j, [X_train, X_test, y_train, y_test] in dic.items():\n",
    "        gradb_reg = GradientBoostingRegressor()\n",
    "        gradb_reg_n[j] = gradb_reg.fit(X_train,y_train)\n",
    "    gradb_reg_dec[i] = gradb_reg_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_dec = {}\n",
    "for i, dic in train_test_dec.items():\n",
    "    y_pred_n = {}\n",
    "    for j, [X_train, X_test, y_train, y_test] in dic.items():\n",
    "        y_pred_n[j] = gradb_reg_dec[i][j].predict(train_test_dec[i][j][1])\n",
    "    y_pred_dec[i]=y_pred_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check error\n",
    "error = {}\n",
    "for i, dic in train_test_dec.items():\n",
    "    err_n = {}\n",
    "    for j, [X_train, X_test, y_train, y_test] in dic.items():\n",
    "        err_n[j] = mean_squared_error(y_test, y_pred_dec[i][j])\n",
    "    error[i]=err_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (5, 26691299144594.914),\n",
       " 1: (25, 107872684.50958434),\n",
       " 2: (5, 100821548317269.16),\n",
       " 3: (5, 92140489772.70012),\n",
       " 4: (30, 5665863916911744.0),\n",
       " 5: (35, 2420419685034184.5),\n",
       " 6: (20, 830917323014.7333),\n",
       " 7: (10, 1468879537764030.5),\n",
       " 8: (5, 495736826888361.06),\n",
       " 9: (5, 122169205572.4949),\n",
       " 10: (15, 103281285744554.27),\n",
       " 11: (10, 84325841380436.4)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for optimal feature number for PCA\n",
    "pca_n = {i:sorted([x for x in dic.items()],key=lambda x: x[1])[0] for i,dic in error.items()}\n",
    "pca_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try optimal Linear Regression for submission\n",
    "y_sub = {}\n",
    "for i, df in X_sub_dec.items():\n",
    "    x = pca[i][pca_n[i]].transform(df)\n",
    "    y_sub[i] = gradb_reg_dec[i][pca_n[i]].predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in y_sub.items():\n",
    "    y_sub[i] = abs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = np.concatenate(list(y_sub.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6245750.06808099, 6236620.94509115, 1645271.99390413, ...,\n",
       "        135706.61069037,  135713.25590025,   14734.16099133])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for submission\n",
    "sub30 = submission\n",
    "sub30['price'] = y_sub/100\n",
    "sub30 = sub30['price']\n",
    "sub30.to_csv('../cars-competition/data/sub_mixPCA_byDecade_hundreth', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
